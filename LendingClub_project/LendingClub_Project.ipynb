{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this project, we will focus on credit modelling, a well known data science problem that focuses on modeling a borrower's credit risk. Credit has played a key role in the economy for centuries and some form of credit has existed since the beginning of commerce. We'll be working with financial lending data from Lending Club. [Lending Club](https://www.lendingclub.com/auth/login?login_url=%2Fstatistics%2Fadditional-statistics%3F) is a marketplace for personal loans that matches borrowers who are seeking a loan with investors looking to lend money and make a return. You can read more about their marketplace [here](https://www.lendingclub.com/public/how-peer-lending-works.action)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are going to build a machine learning model that can accurately predict if a borrower will pay off their loan on time or not. The data we are going to work with is approved loans data from 2007 to 2011, since a good number of the loans have already finished. In the datasets for later years, many of the loans are current and still being paid off. The size of the dataset has been reduced to make it easier to work with, by:\n",
    "- removing the `desc` column which contains a long text explanation for each loan\n",
    "- removing the `url` column which contains a link to each loan on Lending Club which can only be accessed with an investor account\n",
    "- removing all columns containing more than 50% missing values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exporing and Cleaning the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id                                1077501\n",
      "member_id                      1.2966e+06\n",
      "loan_amnt                            5000\n",
      "funded_amnt                          5000\n",
      "funded_amnt_inv                      4975\n",
      "term                            36 months\n",
      "int_rate                           10.65%\n",
      "installment                        162.87\n",
      "grade                                   B\n",
      "sub_grade                              B2\n",
      "emp_title                             NaN\n",
      "emp_length                      10+ years\n",
      "home_ownership                       RENT\n",
      "annual_inc                          24000\n",
      "verification_status              Verified\n",
      "issue_d                          Dec-2011\n",
      "loan_status                    Fully Paid\n",
      "pymnt_plan                              n\n",
      "purpose                       credit_card\n",
      "title                            Computer\n",
      "zip_code                            860xx\n",
      "addr_state                             AZ\n",
      "dti                                 27.65\n",
      "delinq_2yrs                             0\n",
      "earliest_cr_line                 Jan-1985\n",
      "inq_last_6mths                          1\n",
      "open_acc                                3\n",
      "pub_rec                                 0\n",
      "revol_bal                           13648\n",
      "revol_util                          83.7%\n",
      "total_acc                               9\n",
      "initial_list_status                     f\n",
      "out_prncp                               0\n",
      "out_prncp_inv                           0\n",
      "total_pymnt                       5863.16\n",
      "total_pymnt_inv                   5833.84\n",
      "total_rec_prncp                      5000\n",
      "total_rec_int                      863.16\n",
      "total_rec_late_fee                      0\n",
      "recoveries                              0\n",
      "collection_recovery_fee                 0\n",
      "last_pymnt_d                     Jan-2015\n",
      "last_pymnt_amnt                    171.62\n",
      "last_credit_pull_d               Jun-2016\n",
      "collections_12_mths_ex_med              0\n",
      "policy_code                             1\n",
      "application_type               INDIVIDUAL\n",
      "acc_now_delinq                          0\n",
      "chargeoff_within_12_mths                0\n",
      "delinq_amnt                             0\n",
      "pub_rec_bankruptcies                    0\n",
      "tax_liens                               0\n",
      "Name: 0, dtype: object\n",
      "52\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "loans_2007 = pd.read_csv(\"loans_2007.csv\")\n",
    "print(loans_2007.iloc[0])\n",
    "print(len(loans_2007.columns))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Dataframe contains many columns and can be cumbersome to try to explore all at once. Let's break up the columns into 3 groups of 18 columns and use the [data dictionary](https://docs.google.com/spreadsheets/d/191B2yJ4H1ZPXq0_ByhUgWMFZOYem5jFz0Y3by_7YBY4/edit#gid=2081333097) to become familiar with what each column represents.\n",
    "\n",
    "At the moment, let's focus on just columns that we need to remove from consideration. Then, we can circle back and further dissect the columns we decided to keep. We created a table that contains the name, data type, first row's value, and description from the data dictionary for the first 18 rows.\n",
    "\n",
    "|name\t|dtype\t|first value\t|description|\n",
    "|---|---|---|---|\n",
    "|id\t|object\t|1077501\t|A unique LC assigned ID for the loan listing.|\n",
    "|member_id\t|float64\t|1.2966e+06\t|A unique LC assigned Id for the borrower member.|\n",
    "|loan_amnt\t|float64\t|5000\t|The listed amount of the loan applied for by the borrower.|\n",
    "|funded_amnt\t|float64\t|5000\t|The total amount committed to that loan at that point in time.|\n",
    "|funded_amnt_inv\t|float64\t|49750\t|The total amount committed by investors for that loan at that point in time.|\n",
    "|term\t|object\t|36 months\t|The number of payments on the loan. Values are in months and can be either 36 or 60.|\n",
    "|int_rate\t|object\t|10.65%\t|Interest Rate on the loan|\n",
    "|installment\t|float64\t|162.87\t|The monthly payment owed by the borrower if the loan originates.|\n",
    "|grade\t|object\t|B\t|LC assigned loan grade|\n",
    "|sub_grade\t|object\t|B2\t|LC assigned loan subgrade|\n",
    "|emp_title\t|object\t|NaN\t|The job title supplied by the Borrower when applying for the loan.|\n",
    "|emp_length\t|object\t|10+ years\t|Employment length in years. Possible values are between 0 and 10 where 0 means less than one year and 10 means ten or more years.|\n",
    "|home_ownership\t|object\t|RENT\t|The home ownership status provided by the borrower during registration. Our values are: RENT, OWN, MORTGAGE, OTHER.|\n",
    "|annual_inc\t|float64\t|24000\t|The self-reported annual income provided by the borrower during registration.|\n",
    "|verification_status\t|object\t|Verified\t|Indicates if income was verified by LC, not verified, or if the income source was verified|\n",
    "|issue_d\t|object\t|Dec-2011\t|The month which the loan was funded|\n",
    "|loan_status\t|object\t|Charged Off\t|Current status of the loan|\n",
    "|pymnt_plan\t|object\t|n\t|Indicates if a payment plan has been put in place for the loan|\n",
    "|purpose\t|object\t|car\t|A category provided by the borrower for the loan request.|\n",
    "\n",
    "After analyzing each column, we can conclude that the following features need to be removed:\n",
    "\n",
    "- `id`: randomly generated field by Lending Club for unique identification purposes only\n",
    "- `member_id`: also a randomly generated field by Lending Club for unique identification purposes only\n",
    "- `funded_amnt`: leaks data from the future (after the loan is already started to be funded)\n",
    "- `funded_amnt_inv`: also leaks data from the future (after the loan is already started to be funded)\n",
    "- `grade`: contains redundant information as the interest rate column (`int_rate`)\n",
    "- `sub_grade`: also contains redundant information as the interest rate column (`int_rate`)\n",
    "- `emp_title`: requires other data and a lot of processing to potentially be useful\n",
    "- `issue_d`: leaks data from the future (after the loan is already completely funded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "loans_2007 = loans_2007.drop([\"id\", \"member_id\", \"funded_amnt\", \"funded_amnt_inv\", \"grade\", \"sub_grade\", \"emp_title\", \"issue_d\"], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now look at the next 18 columns:\n",
    "\n",
    "|name\t|dtype\t|first value\t|description|\n",
    "|---|---|---|---|\n",
    "|title\t|object\t|Computer\t|The loan title provided by the borrower|\n",
    "|zip_code\t|object\t|860xx\t|The first 3 numbers of the zip code provided by the borrower in the loan application.|\n",
    "|addr_state\t|object\t|AZ\t|The state provided by the borrower in the loan application|\n",
    "|dti\t|float64\t|27.65\t|A ratio calculated using the borrower’s total monthly debt payments on the total debt obligations, excluding mortgage and the requested LC loan, divided by the borrower’s self-reported monthly income.|\n",
    "|delinq_2yrs\t|float64\t|0\t|The number of 30+ days past-due incidences of delinquency in the borrower's credit file for the past 2 years|\n",
    "|earliest_cr_line\t|object\t|Jan-1985\t|The month the borrower's earliest reported credit line was opened|\n",
    "|inq_last_6mths\t|float64\t|1\t|The number of inquiries in past 6 months (excluding auto and mortgage inquiries)|\n",
    "|open_acc\t|float64\t|3\t|The number of open credit lines in the borrower's credit file.|\n",
    "|pub_rec\t|float64\t|0\t|Number of derogatory public records|\n",
    "|revol_bal\t|float64\t|13648\t|Total credit revolving balance|\n",
    "|revol_util\t|object\t|83.7%\t|Revolving line utilization rate, or the amount of credit the borrower is using relative to all available revolving credit.|\n",
    "|total_acc\t|float64\t|9\t|The total number of credit lines currently in the borrower's credit file|\n",
    "|initial_list_status\t|object\t|f\t|The initial listing status of the loan. Possible values are – W, F|\n",
    "|out_prncp\t|float64\t|0\t|Remaining outstanding principal for total amount funded|\n",
    "|out_prncp_inv\t|float64\t|0\t|Remaining outstanding principal for portion of total amount funded by investors|\n",
    "|total_pymnt\t|float64\t|5863.16\t|Payments received to date for total amount funded|\n",
    "|total_pymnt_inv\t|float64\t|5833.84\t|Payments received to date for portion of total amount funded by investors|\n",
    "|total_rec_prncp\t|float64\t|5000\t|Principal received to date|\n",
    "\n",
    "Within this group of columns, we need to drop the following columns:\n",
    "\n",
    "- `zip_code`: redundant with the addr_state column since only the first 3 digits of the 5 digit zip code are visible (which only can be used to identify the state the borrower lives in)\n",
    "- `out_prncp`: leaks data from the future, (after the loan already started to be paid off)\n",
    "- `out_prncp_inv`: also leaks data from the future, (after the loan already started to be paid off)\n",
    "- `total_pymnt`: also leaks data from the future, (after the loan already started to be paid off)\n",
    "- `total_pymnt_inv`: also leaks data from the future, (after the loan already started to be paid off)\n",
    "- `total_rec_prncp`: also leaks data from the future, (after the loan already started to be paid off)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "loans_2007 = loans_2007.drop([\"zip_code\", \"out_prncp\", \"out_prncp_inv\", \"total_pymnt\", \"total_pymnt_inv\", \"total_rec_prncp\"], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now move on to the last group of features:\n",
    "\n",
    "|name\t|dtype\t|first value\t|description|\n",
    "|---|---|---|---|\n",
    "|total_rec_int\t|float64\t|863.16\t|Interest received to date|\n",
    "|total_rec_late_fee\t|float64\t|0\t|Late fees received to date|\n",
    "|recoveries\t|float64\t|0\t|post charge off gross recovery|\n",
    "|collection_recovery_fee\t|float64\t|0\t|post charge off collection fee|\n",
    "|last_pymnt_d\t|object\t|Jan-2015\t|Last month payment was received|\n",
    "|last_pymnt_amnt\t|float64\t|171.62\t|Last total payment amount received|\n",
    "|last_credit_pull_d\t|object\t|Jun-2016\t|The most recent month LC pulled credit for this loan|\n",
    "|collections_12_mths_ex_med\t|float64\t|0\t|Number of collections in 12 months excluding medical collections|\n",
    "|policy_code\t|float64\t|1\t|publicly available policy_code=1 new products not publicly available policy_code=2|\n",
    "|application_type\t|object\t|INDIVIDUAL\t|Indicates whether the loan is an individual application or a joint application with two co-borrowers|\n",
    "|acc_now_delinq\t|float64\t|0\t|The number of accounts on which the borrower is now delinquent.|\n",
    "|chargeoff_within_12_mths\t|float64\t|0\t|Number of charge-offs within 12 months|\n",
    "|delinq_amnt\t|float64\t|0\t|The past-due amount owed for the accounts on which the borrower is now delinquent.|\n",
    "|pub_rec_bankruptcies\t|float64\t|0\t|Number of public record bankruptcies|\n",
    "|tax_liens\t|float64\t|0\t|Number of tax liens|\n",
    "\n",
    "In the last group of columns, we need to drop the following columns:\n",
    "\n",
    "- `total_rec_int`: leaks data from the future, (after the loan already started to be paid off),\n",
    "- `total_rec_late_fee`: also leaks data from the future, (after the loan already started to be paid off),\n",
    "- `recoveries`: also leaks data from the future, (after the loan already started to be paid off),\n",
    "- `collection_recovery_fee`: also leaks data from the future, (after the loan already started to be paid off),\n",
    "- `last_pymnt_d`: also leaks data from the future, (after the loan already started to be paid off),\n",
    "- `last_pymnt_amnt`: also leaks data from the future, (after the loan already started to be paid off)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loan_amnt                            5000\n",
      "term                            36 months\n",
      "int_rate                           10.65%\n",
      "installment                        162.87\n",
      "emp_length                      10+ years\n",
      "home_ownership                       RENT\n",
      "annual_inc                          24000\n",
      "verification_status              Verified\n",
      "loan_status                    Fully Paid\n",
      "pymnt_plan                              n\n",
      "purpose                       credit_card\n",
      "title                            Computer\n",
      "addr_state                             AZ\n",
      "dti                                 27.65\n",
      "delinq_2yrs                             0\n",
      "earliest_cr_line                 Jan-1985\n",
      "inq_last_6mths                          1\n",
      "open_acc                                3\n",
      "pub_rec                                 0\n",
      "revol_bal                           13648\n",
      "revol_util                          83.7%\n",
      "total_acc                               9\n",
      "initial_list_status                     f\n",
      "last_credit_pull_d               Jun-2016\n",
      "collections_12_mths_ex_med              0\n",
      "policy_code                             1\n",
      "application_type               INDIVIDUAL\n",
      "acc_now_delinq                          0\n",
      "chargeoff_within_12_mths                0\n",
      "delinq_amnt                             0\n",
      "pub_rec_bankruptcies                    0\n",
      "tax_liens                               0\n",
      "Name: 0, dtype: object\n",
      "32\n"
     ]
    }
   ],
   "source": [
    "loans_2007 = loans_2007.drop([\"total_rec_int\", \"total_rec_late_fee\", \"recoveries\", \"collection_recovery_fee\", \"last_pymnt_d\", \"last_pymnt_amnt\"], axis=1)\n",
    "print(loans_2007.iloc[0])\n",
    "print(loans_2007.shape[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just by becoming familiar with the columns in the dataset, we were able to reduce the number of columns from 52 to 32 columns. We now need to decide on a target column that we want to use for modeling.\n",
    "\n",
    "We should use the `loan_status` column, since it's the only column that directly describes if a loan was paid off on time, had delayed payments, or was defaulted on the borrower. Currently, this column contains text values and we need to convert it to a numerical one for training a model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fully Paid                                             33136\n",
      "Charged Off                                             5634\n",
      "Does not meet the credit policy. Status:Fully Paid      1988\n",
      "Current                                                  961\n",
      "Does not meet the credit policy. Status:Charged Off      761\n",
      "Late (31-120 days)                                        24\n",
      "In Grace Period                                           20\n",
      "Late (16-30 days)                                          8\n",
      "Default                                                    3\n",
      "NaN                                                        3\n",
      "Name: loan_status, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(loans_2007[\"loan_status\"].value_counts(dropna=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are 8 different possible values for the `loan_status` column. Their meanings are explained below:\n",
    "\n",
    "- Fully Paid: Loan has been fully paid off.\n",
    "- Charged Off: Loan for which there is no longer a reasonable expectation of further payments.\n",
    "- Does not meet the credit policy. Status:Fully Paid: While the loan was paid off, the loan application today would no longer meet the credit policy and wouldn't be approved on to the marketplace.\n",
    "- Does not meet the credit policy. Status:Charged Off: While the loan was charged off, the loan application today would no longer meet the credit policy and wouldn't be approved on to the marketplace.\n",
    "- In Grace Period: The loan is past due but still in the grace period of 15 days.\n",
    "- Late (16-30 days): Loan hasn't been paid in 16 to 30 days (late on the current payment).\n",
    "- Late (31-120 days): Loan hasn't been paid in 31 to 120 days (late on the current payment).\n",
    "- Current: Loan is up to date on current payments.\n",
    "- Default: Loan is defaulted on and no payment has been made for more than 121 days.\n",
    "\n",
    "From the investor's perspective, we're interested in trying to predict which loans will be paid off on time and which ones won't be. Only the `Fully Paid` and `Charged Off` values describe the final outcome of the loan. The other values describe loans that are still ongoing and where the jury is still out on if the borrower will pay back the loan on time or not. Since we're interested in being able to predict which of these 2 values a loan will fall under, we can treat the problem as a binary classification one. Let's remove all the loans that don't contain either `Fully Paid` and `Charged Off` as the loan's status and then transform the `Fully Paid` values to 1 for the positive case and the `Charged Off` values to 0 for the negative case. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "loans_2007 = loans_2007[(loans_2007[\"loan_status\"] == \"Fully Paid\") | (loans_2007[\"loan_status\"] == \"Charged Off\")]\n",
    "\n",
    "mapping_dict = {\"loan_status\":{\"Fully Paid\":1, \"Charged Off\":0}}\n",
    "\n",
    "loans_2007 = loans_2007.replace(mapping_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To wrap up this section, let's look for any columns that contain only one unique value and remove them. These columns won't be useful for the model since they don't add any information to each loan application. In addition, removing these columns will reduce the number of columns we'll need to explore further."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['pymnt_plan', 'initial_list_status', 'collections_12_mths_ex_med', 'policy_code', 'application_type', 'acc_now_delinq', 'chargeoff_within_12_mths', 'delinq_amnt', 'tax_liens']\n"
     ]
    }
   ],
   "source": [
    "drop_columns = []\n",
    "\n",
    "for column in loans_2007.columns:\n",
    "    loans_2007[column] = loans_2007[column].dropna()\n",
    "    if loans_2007[column].nunique() == 1:\n",
    "        drop_columns.append(column)\n",
    "        \n",
    "loans = loans_2007.drop(drop_columns, axis=1)\n",
    "print(drop_columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It looks we were able to remove 9 more columns since they only contained 1 unique value.\n",
    "\n",
    "In this section, we started to become familiar with the columns in the dataset and removed many columns that aren't useful for modeling. We also selected our target column and decided to focus our modeling efforts on binary classification. In the next section, we'll explore the individual features in greater depth and work towards training our machine learning model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparing the Features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's start by computing the number of missing values and come up with a strategy for handling them. Then, we'll focus on the categorical columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "emp_length              1036\n",
      "title                     11\n",
      "revol_util                50\n",
      "last_credit_pull_d         2\n",
      "pub_rec_bankruptcies     697\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "null_counts = loans.isnull().sum()\n",
    "\n",
    "print(null_counts[null_counts > 0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While most of the columns have no missing values, two columns have fifty or less rows with missing values, and two columns, `emp_length` and `pub_rec_bankruptcies`, contain a relatively high amount of missing values.\n",
    "\n",
    "Domain knowledge tells us that employment length is frequently used in assessing how risky a potential borrower is, so we'll keep this column despite its relatively large amount of missing values.\n",
    "\n",
    "Let's inspect the values of the column `pub_rec_bankruptcies`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0    0.939438\n",
      "1.0    0.042456\n",
      "NaN    0.017978\n",
      "2.0    0.000129\n",
      "Name: pub_rec_bankruptcies, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(loans[\"pub_rec_bankruptcies\"].value_counts(normalize=True, dropna=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that this column offers very little variability, nearly 94% of values are in the same category. It probably won't have much predictive value. Let's drop it. In addition, we'll remove the remaining rows containing null values.\n",
    "\n",
    "This means that we'll keep the following columns and just remove rows containing missing values for them: `emp_length`, `title`, `revol_util`, `last_credit_pull_d` and drop the `pub_rec_bankruptcies` column entirely."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "object     11\n",
      "float64    10\n",
      "int64       1\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "loans = loans.drop(\"pub_rec_bankruptcies\", axis=1)\n",
    "loans = loans.dropna(axis=0)\n",
    "print(loans.dtypes.value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While the numerical columns can be used natively with scikit-learn, the object columns that contain text need to be converted to numerical data types. Let's return a new Dataframe containing just the object columns so we can explore them in more depth. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "term                     36 months\n",
      "int_rate                    10.65%\n",
      "emp_length               10+ years\n",
      "home_ownership                RENT\n",
      "verification_status       Verified\n",
      "purpose                credit_card\n",
      "title                     Computer\n",
      "addr_state                      AZ\n",
      "earliest_cr_line          Jan-1985\n",
      "revol_util                   83.7%\n",
      "last_credit_pull_d        Jun-2016\n",
      "Name: 0, dtype: object\n"
     ]
    }
   ],
   "source": [
    "object_columns_df = loans.select_dtypes(include=[\"object\"])\n",
    "print(object_columns_df.iloc[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some of the columns seem like they represent categorical values, but we should confirm by checking the number of unique values in those columns:\n",
    "\n",
    "- `home_ownership`: home ownership status, can only be 1 of 4 categorical values according to the data dictionary\n",
    "- `verification_status`: indicates if income was verified by Lending Club\n",
    "- `emp_length`: number of years the borrower was employed upon time of application\n",
    "- `term`: number of payments on the loan, either 36 or 60\n",
    "- `addr_state`: borrower's state of residence\n",
    "- `purpose`: a category provided by the borrower for the loan request\n",
    "- `title`: loan title provided by the borrower\n",
    "\n",
    "There are also some columns that represent numeric values, that need to be converted:\n",
    "\n",
    "- `int_rate`: interest rate of the loan in %\n",
    "- `revol_util`: revolving line utilization rate or the amount of credit the borrower is using relative to all available credit\n",
    "\n",
    "Based on the first row's values for `purpose` and `title`, it seems like these columns could reflect the same information. Let's explore the unique value counts separately to confirm if this is true.\n",
    "\n",
    "Lastly, some of the columns contain date values that would require a good amount of feature engineering for them to be potentially useful:\n",
    "\n",
    "- `earliest_cr_line`: The month the borrower's earliest reported credit line was opened,\n",
    "- `last_credit_pull_d`: The most recent month Lending Club pulled credit for this loan.\n",
    "\n",
    "Since these date features require some feature engineering for modeling purposes, let's remove these date columns from the Dataframe."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Checking categorical columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RENT        18112\n",
      "MORTGAGE    16686\n",
      "OWN          2778\n",
      "OTHER          96\n",
      "NONE            3\n",
      "Name: home_ownership, dtype: int64\n",
      "\n",
      "\n",
      "Not Verified       16281\n",
      "Verified           11856\n",
      "Source Verified     9538\n",
      "Name: verification_status, dtype: int64\n",
      "\n",
      "\n",
      "10+ years    8545\n",
      "< 1 year     4513\n",
      "2 years      4303\n",
      "3 years      4022\n",
      "4 years      3353\n",
      "5 years      3202\n",
      "1 year       3176\n",
      "6 years      2177\n",
      "7 years      1714\n",
      "8 years      1442\n",
      "9 years      1228\n",
      "Name: emp_length, dtype: int64\n",
      "\n",
      "\n",
      " 36 months    28234\n",
      " 60 months     9441\n",
      "Name: term, dtype: int64\n",
      "\n",
      "\n",
      "CA    6776\n",
      "NY    3614\n",
      "FL    2704\n",
      "TX    2613\n",
      "NJ    1776\n",
      "IL    1447\n",
      "PA    1442\n",
      "VA    1347\n",
      "GA    1323\n",
      "MA    1272\n",
      "OH    1149\n",
      "MD    1008\n",
      "AZ     807\n",
      "WA     788\n",
      "CO     748\n",
      "NC     729\n",
      "CT     711\n",
      "MI     678\n",
      "MO     648\n",
      "MN     581\n",
      "NV     466\n",
      "SC     454\n",
      "WI     427\n",
      "OR     422\n",
      "LA     420\n",
      "AL     420\n",
      "KY     311\n",
      "OK     285\n",
      "KS     249\n",
      "UT     249\n",
      "AR     229\n",
      "DC     209\n",
      "RI     194\n",
      "NM     180\n",
      "WV     164\n",
      "HI     162\n",
      "NH     157\n",
      "DE     110\n",
      "MT      77\n",
      "AK      76\n",
      "WY      76\n",
      "SD      60\n",
      "VT      53\n",
      "MS      19\n",
      "TN      17\n",
      "IN       9\n",
      "ID       6\n",
      "IA       5\n",
      "NE       5\n",
      "ME       3\n",
      "Name: addr_state, dtype: int64\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cols = ['home_ownership', 'verification_status', 'emp_length', 'term', 'addr_state']\n",
    "\n",
    "for col in cols:\n",
    "    print(loans[col].value_counts())\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All 5 columns contain multiple discrete values. We should clean the emp_length column and treat it as a numerical one since the values have ordering (2 years of employment is less than 8 years).\n",
    "\n",
    "First, let's look at the unique value counts for the `purpose` and `title` columns to understand which column we want to keep."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Debt Consolidation                          2068\n",
      "Debt Consolidation Loan                     1599\n",
      "Personal Loan                                624\n",
      "Consolidation                                488\n",
      "debt consolidation                           466\n",
      "                                            ... \n",
      "Great Credit Individual Seeking Loan           1\n",
      "Consolidate after home purchase & repair       1\n",
      "big money                                      1\n",
      "Windows keep the heat                          1\n",
      "30 Year Roof Needs Replacing After 40          1\n",
      "Name: title, Length: 18881, dtype: int64\n",
      "\n",
      "\n",
      "debt_consolidation    17751\n",
      "credit_card            4911\n",
      "other                  3711\n",
      "home_improvement       2808\n",
      "major_purchase         2083\n",
      "small_business         1719\n",
      "car                    1459\n",
      "wedding                 916\n",
      "medical                 655\n",
      "moving                  552\n",
      "house                   356\n",
      "vacation                348\n",
      "educational             312\n",
      "renewable_energy         94\n",
      "Name: purpose, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(loans[\"title\"].value_counts())\n",
    "print(\"\\n\")\n",
    "print(loans[\"purpose\"].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `home_ownership`, `verification_status`, `emp_length`, and `term` columns each contain a few discrete categorical values. We should encode these columns as dummy variables and keep them.\n",
    "\n",
    "It seems like the `purpose` and `title` columns do contain overlapping information but we'll keep the `purpose` column since it contains a few discrete values. In addition, the `title` column has data quality issues since many of the values are repeated with slight modifications (e.g. `Debt Consolidation` and `Debt Consolidation Loan` and `debt consolidation`).\n",
    "\n",
    "Lastly, the `addr_state` column contains many discrete values and we'd need to add 49 dummy variable columns to use it for classification. This would make our Dataframe much larger and could slow down how quickly the code runs. Let's remove this column from consideration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop unwanted columns, convert to numerical data type\n",
    "mapping_dict = {\n",
    "    \"emp_length\": {\n",
    "        \"10+ years\": 10,\n",
    "        \"9 years\": 9,\n",
    "        \"8 years\": 8,\n",
    "        \"7 years\": 7,\n",
    "        \"6 years\": 6,\n",
    "        \"5 years\": 5,\n",
    "        \"4 years\": 4,\n",
    "        \"3 years\": 3,\n",
    "        \"2 years\": 2,\n",
    "        \"1 year\": 1,\n",
    "        \"< 1 year\": 0,\n",
    "        \"n/a\": 0\n",
    "    }\n",
    "}\n",
    "\n",
    "loans = loans.drop([\"last_credit_pull_d\", \"addr_state\", \"title\", \"earliest_cr_line\"], axis=1)\n",
    "\n",
    "loans[\"int_rate\"] = loans[\"int_rate\"].str.rstrip(\"%\").astype(float)\n",
    "loans[\"revol_util\"] = loans[\"revol_util\"].str.rstrip(\"%\").astype(float)\n",
    "\n",
    "loans = loans.replace(mapping_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to dummy columns\n",
    "dummy_cols = [\"home_ownership\", \"verification_status\", \"purpose\", \"term\"]\n",
    "\n",
    "dummy_df = pd.get_dummies(loans[dummy_cols])\n",
    "loans = pd.concat([loans, dummy_df], axis=1)\n",
    "loans = loans.drop(dummy_cols, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section, we performed the last amount of data preparation necessary to start training machine learning models. We converted all of the columns to numerical values because those are the only type of value scikit-learn can work with. In the next section, we'll experiment with training models and evaluating accuracy using cross-validation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Making Predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our eventual goal is to generate features from the data, which can feed into a machine learning algorithm. The algorithm will make predictions about whether or not a loan will be paid off on time, which is contained in the `loan_status` column of the clean dataset.\n",
    "\n",
    "As we prepared the data, we removed columns that had data leakage issues, contained redundant information, or required additional processing to turn into useful features. We cleaned features that had formatting issues, and converted categorical columns to dummy variables.\n",
    "\n",
    "We noticed that there's a class imbalance in our target column, `loan_status`. There are about 6 times as many loans that were paid off on time (positive case, label of 1) than those that weren't (negative case, label of 0). Imbalances can cause issues with many machine learning algorithms, where they appear to have high accuracy, but actually aren't learning from the training data. Because of its potential to cause issues, we need to keep the class imbalance in mind as we build machine learning models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 37675 entries, 0 to 37674\n",
      "Data columns (total 38 columns):\n",
      " #   Column                               Non-Null Count  Dtype  \n",
      "---  ------                               --------------  -----  \n",
      " 0   loan_amnt                            37675 non-null  float64\n",
      " 1   int_rate                             37675 non-null  float64\n",
      " 2   installment                          37675 non-null  float64\n",
      " 3   emp_length                           37675 non-null  int64  \n",
      " 4   annual_inc                           37675 non-null  float64\n",
      " 5   loan_status                          37675 non-null  int64  \n",
      " 6   dti                                  37675 non-null  float64\n",
      " 7   delinq_2yrs                          37675 non-null  float64\n",
      " 8   inq_last_6mths                       37675 non-null  float64\n",
      " 9   open_acc                             37675 non-null  float64\n",
      " 10  pub_rec                              37675 non-null  float64\n",
      " 11  revol_bal                            37675 non-null  float64\n",
      " 12  revol_util                           37675 non-null  float64\n",
      " 13  total_acc                            37675 non-null  float64\n",
      " 14  home_ownership_MORTGAGE              37675 non-null  int64  \n",
      " 15  home_ownership_NONE                  37675 non-null  int64  \n",
      " 16  home_ownership_OTHER                 37675 non-null  int64  \n",
      " 17  home_ownership_OWN                   37675 non-null  int64  \n",
      " 18  home_ownership_RENT                  37675 non-null  int64  \n",
      " 19  verification_status_Not Verified     37675 non-null  int64  \n",
      " 20  verification_status_Source Verified  37675 non-null  int64  \n",
      " 21  verification_status_Verified         37675 non-null  int64  \n",
      " 22  purpose_car                          37675 non-null  int64  \n",
      " 23  purpose_credit_card                  37675 non-null  int64  \n",
      " 24  purpose_debt_consolidation           37675 non-null  int64  \n",
      " 25  purpose_educational                  37675 non-null  int64  \n",
      " 26  purpose_home_improvement             37675 non-null  int64  \n",
      " 27  purpose_house                        37675 non-null  int64  \n",
      " 28  purpose_major_purchase               37675 non-null  int64  \n",
      " 29  purpose_medical                      37675 non-null  int64  \n",
      " 30  purpose_moving                       37675 non-null  int64  \n",
      " 31  purpose_other                        37675 non-null  int64  \n",
      " 32  purpose_renewable_energy             37675 non-null  int64  \n",
      " 33  purpose_small_business               37675 non-null  int64  \n",
      " 34  purpose_vacation                     37675 non-null  int64  \n",
      " 35  purpose_wedding                      37675 non-null  int64  \n",
      " 36  term_ 36 months                      37675 non-null  int64  \n",
      " 37  term_ 60 months                      37675 non-null  int64  \n",
      "dtypes: float64(12), int64(26)\n",
      "memory usage: 10.9 MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# The cleaned data from previous steps are stored in cleaned_loans_2007.csv\n",
    "loans = pd.read_csv(\"cleaned_loans_2007.csv\")\n",
    "print(loans.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Picking an error metric"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We established our question \"Can we build a machine learning model that can accurately predict if a borrower will pay off their loan on time or not?\" as a binary classification problem. Before diving in and selecting an algorithm to apply to the data, we should select an error metric.\n",
    "\n",
    "An error metric will help us figure out when our model is performing well, and when it's performing poorly. To tie error metrics all the way back to the original question we wanted to answer, let's say we're using a machine learning model to predict whether or not we should fund a loan on the Lending Club platform. Our objective in this is to make money -- we want to fund enough loans that are paid off on time to offset our losses from loans that aren't paid off. An error metric will help us determine if our algorithm will make us money or lose us money.\n",
    "\n",
    "In this case, we're primarily concerned with false positives and false negatives. Both of these are different types of misclassifications. With a false positive, we predict that a loan will be paid off on time, but it actually isn't. This costs us money, since we fund loans that lose us money. With a false negative, we predict that a loan won't be paid off on time, but it actually would be paid off on time. This loses us potential money, since we didn't fund a loan that actually would have been paid off.\n",
    "\n",
    "Since we're viewing this problem from the standpoint of a conservative investor, we need to treat false positives differently than false negatives. A conservative investor would want to minimize risk, and avoid false positives as much as possible. They'd be more okay with missing out on opportunities (false negatives) than they would be with funding a risky loan (false positives)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We mentioned earlier that there is a significant class imbalance in the loan_status column. There are 6 times as many loans that were paid off on time (1), than loans that weren't paid off on time (0). This causes a major issue when we use accuracy as a metric. This is because due to the class imbalance, a classifier can predict 1 for every row, and still have high accuracy. In this case, we don't want to use accuracy, and should instead use metrics that tell us the number of false positives and false negatives.\n",
    "\n",
    "This means that we should optimize for:\n",
    "\n",
    "- high recall (true positive rate)\n",
    "- low fall-out (false positive rate)\n",
    "\n",
    "We can calculate false positive rate and true positive rate, using the numbers of true positives, true negatives, false negatives, and false positives.\n",
    "\n",
    "False positive rate is the number of false positives divided by the number of false positives plus the number of true negatives. This divides all the cases where we thought a loan would be paid off but it wasn't by all the loans that weren't paid off: fpr = fp / (fp + tn)\n",
    "\n",
    "True positive rate is the number of true positives divided by the number of true positives plus the number of false negatives. This divides all the cases where we thought a loan would be paid off and it was by all the loans that were paid off: tpr = tp / (tp + fn)\n",
    "\n",
    "Simple english ways to think of each term are:\n",
    "\n",
    "- False Positive Rate: \"the percentage of the loans that shouldn't be funded that I would fund\".\n",
    "- True Positive Rate: \"the percentage of loans that should be funded that I would fund\".\n",
    "\n",
    "Generally, if we want to reduce false positive rate, true positive rate will also go down. This is because if we want to reduce the risk of false positives, we wouldn't think about funding riskier loans in the first place."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Picking machine learning models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we saw in the first screen of the mission, our cleaned dataset contains 41 columns, all of which are either the int64 or the float64 data type. There aren't any null values in any of the columns. This means that we can now apply any machine learning algorithm to our dataset.\n",
    "\n",
    "A good first algorithm to apply to binary classification problems is logistic regression, for the following reasons:\n",
    "\n",
    "- it's quick to train and we can iterate more quickly,\n",
    "- it's less prone to overfitting than more complex models like decision trees,\n",
    "- it's easy to interpret."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = loans.columns\n",
    "train_cols = cols.drop(\"loan_status\")\n",
    "\n",
    "features = loans[train_cols]\n",
    "target = loans[\"loan_status\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5418447624357307\n",
      "0.31712748190758955\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "\n",
    "# With class_weight set to balanced, scikit-learn will penalize the misclassification of the minority class during the training \n",
    "# process in order to combat class imbalances\n",
    "lr = LogisticRegression(class_weight=\"balanced\", max_iter=200)\n",
    "# Make predictions using 3-fold cross-validation.\n",
    "predictions = cross_val_predict(lr, features, target, cv=3)\n",
    "predictions = pd.Series(predictions)\n",
    "\n",
    "tp_filter = (predictions == 1) & (loans[\"loan_status\"] == 1)\n",
    "fp_filter = (predictions == 1) & (loans[\"loan_status\"] == 0)\n",
    "tn_filter = (predictions == 0) & (loans[\"loan_status\"] == 0)\n",
    "fn_filter = (predictions == 0) & (loans[\"loan_status\"] == 1)\n",
    "\n",
    "tp_num = len(predictions[tp_filter])\n",
    "fp_num = len(predictions[fp_filter])\n",
    "tn_num = len(predictions[tn_filter])\n",
    "fn_num = len(predictions[fn_filter])\n",
    "\n",
    "tpr = tp_num / (tp_num + fn_num)\n",
    "fpr = fp_num / (fp_num + tn_num)\n",
    "\n",
    "print(tpr)\n",
    "print(fpr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our true positive rate is now around 54%, and our false positive rate is around 32%. From a conservative investor's standpoint, it's reassuring that the false positive rate is lower because it means that we'll be able to do a better job at avoiding bad loans than if we funded everything. However, we'd only ever decide to fund 54% of the total loans (true positive rate), so we'd immediately reject a good amount of loans.\n",
    "\n",
    "We can try to lower the false positive rate further by assigning a harsher penalty for misclassifying the negative class. While setting class_weight to balanced will automatically set a penalty based on the number of 1s and 0s in the column, we can also set a manual penalty. In the last screen, the penalty scikit-learn imposed for misclassifying a 0 would have been around 5.89 (since there are 5.89 times as many 1s as 0s).\n",
    "\n",
    "We can also specify a penalty manually if we want to adjust the rates more. To do this, we need to pass in a dictionary of penalty values to the class_weight parameter:\n",
    "\n",
    "penalty = {0: 10, 1: 1}\n",
    "\n",
    "lr = LogisticRegression(class_weight=penalty)\n",
    "\n",
    "The above dictionary will impose a penalty of 10 for misclassifying a 0, and a penalty of 1 for misclassifying a 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.16750294245183672\n",
      "0.06977175728335498\n"
     ]
    }
   ],
   "source": [
    "penalty = {\n",
    "    0: 10,\n",
    "    1: 1\n",
    "}\n",
    "\n",
    "lr = LogisticRegression(class_weight=penalty, max_iter=200)\n",
    "\n",
    "predictions = cross_val_predict(lr, features, target, cv=3)\n",
    "predictions = pd.Series(predictions)\n",
    "\n",
    "tp_filter = (predictions == 1) & (loans[\"loan_status\"] == 1)\n",
    "fp_filter = (predictions == 1) & (loans[\"loan_status\"] == 0)\n",
    "tn_filter = (predictions == 0) & (loans[\"loan_status\"] == 0)\n",
    "fn_filter = (predictions == 0) & (loans[\"loan_status\"] == 1)\n",
    "\n",
    "tp_num = len(predictions[tp_filter])\n",
    "fp_num = len(predictions[fp_filter])\n",
    "tn_num = len(predictions[tn_filter])\n",
    "fn_num = len(predictions[fn_filter])\n",
    "\n",
    "tpr = tp_num / (tp_num + fn_num)\n",
    "fpr = fp_num / (fp_num + tn_num)\n",
    "\n",
    "print(tpr)\n",
    "print(fpr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It looks like assigning manual penalties lowered the false positive rate to 7%, and thus lowered our risk. Note that this comes at the expense of true positive rate. While we have fewer false positives, we're also missing opportunities to fund more loans and potentially make more money. Given that we're approaching this as a conservative investor, this strategy makes sense, but it's worth keeping in mind the tradeoffs.\n",
    "\n",
    "Let's try a more complex algorithm, random forest.  Random forests are able to work with nonlinear data, and learn complex conditionals. Logistic regressions are only able to work with linear data. Training a random forest algorithm may enable us to get more accuracy due to columns that correlate nonlinearly with `loan_status`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9977079848850895\n",
      "0.9918352198923733\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rf = RandomForestClassifier(class_weight=\"balanced\", random_state=1)\n",
    "predictions = cross_val_predict(rf, features, target, cv=3)\n",
    "predictions = pd.Series(predictions)\n",
    "\n",
    "tp_filter = (predictions == 1) & (loans[\"loan_status\"] == 1)\n",
    "fp_filter = (predictions == 1) & (loans[\"loan_status\"] == 0)\n",
    "tn_filter = (predictions == 0) & (loans[\"loan_status\"] == 0)\n",
    "fn_filter = (predictions == 0) & (loans[\"loan_status\"] == 1)\n",
    "\n",
    "tp_num = len(predictions[tp_filter])\n",
    "fp_num = len(predictions[fp_filter])\n",
    "tn_num = len(predictions[tn_filter])\n",
    "fn_num = len(predictions[fn_filter])\n",
    "\n",
    "tpr = tp_num / (tp_num + fn_num)\n",
    "fpr = fp_num / (fp_num + tn_num)\n",
    "\n",
    "print(tpr)\n",
    "print(fpr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unfortunately, using a random forest classifier didn't improve our false positive rate. The model is likely weighting too heavily on the 1 class, and still mostly predicting 1s. We could fix this by applying a harsher penalty for misclassifications of 0s.\n",
    "\n",
    "Ultimately, our best model had a false positive rate of nearly 7%, and a true positive rate of nearly 17%. For a conservative investor, this means that they make money as long as the interest rate is high enough to offset the losses from 7% of borrowers defaulting, and that the pool of 17% of borrowers is large enough to make enough interest money to offset the losses.\n",
    "\n",
    "If we had randomly picked loans to fund, borrowers would have defaulted on 14.5% of them, and our model is better than that, although we're excluding more loans than a random strategy would."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
